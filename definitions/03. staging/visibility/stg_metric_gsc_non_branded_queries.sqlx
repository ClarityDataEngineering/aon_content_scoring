config {
    type: 'view',
    schema: project_config.OUTPUT_STAGING_DATASET, 
    description: 'Weekly GSC branded queries volume per page with 12-month rolling total, months live, monthly average, and weekly relative percentile-based scoring.',
    bigquery: {
        labels: {
          table_name: "content_scoring_stg_metric_gsc_branded_queries"
        }
    }
}



-- Get base clicks and calculate at weekly cadence
with base_queries as (
    select
        date_trunc(date, week(MONDAY)) as event_date_dt
        , page_location_clean
        , count(distinct(query)) as unique_queries
    from 
        ${ref('fct_gsc_url_report')}
    where
        regexp_contains(page_location_clean, r'${project_config.PAGES_TO_INCLUDE_RX}')
        and query_type = 'Non-Branded'
        and date >= "${project_config.START_DATE}"
    group by 
        event_date_dt
        , page_location_clean
)

-- Join with weekly scaffold 
, base_live_queries as (
    select
        sc.event_date_dt
        , sc.page_location_clean
        , coalesce(bs.unique_queries, 0) as unique_queries
        , sc.first_seen_date
        , sc.months_live
    from 
        ${ref('stg_ga4_page_live_weekly_scaffold')} sc
    left join 
        base_queries bs
        using (event_date_dt, page_location_clean)
    where
        sc.is_page_live_week = true  -- Only include pages where the page is live in a given week
)

-- Use window function to calculate a 12 month rolling looking back over last 52 rows
, rolling_12_month as (
    select
        event_date_dt
        , page_location_clean
        , first_seen_date
        , months_live
        , sum(unique_queries) over (partition by page_location_clean order by event_date_dt rows between 51 preceding and current row) as total_12_months
    from 
        base_live_queries
)

-- Join the months live and calculate the monthly avg. Add filter to include rows only post first seen date
, calc_monthly_avg as (
    select
        event_date_dt
        , page_location_clean
        , total_12_months
        , months_live
        , first_seen_date
        -- Divide by months live, though if months live is greater than 12 then return 12
        , cast(round(safe_divide(total_12_months, least(months_live, 12))) as int64) as monthly_avg
    from 
        rolling_12_month
    where
        event_date_dt >= first_seen_date
)
-- Calculate the percentiles at a weekly cadence based on 12 month rolling avg  
, weekly_percentiles as (
    select
        event_date_dt
        , page_location_clean
        , total_12_months
        , months_live
        , first_seen_date
        , monthly_avg
        , cast(round(percentile_cont(monthly_avg, 0.80) over(partition by event_date_dt)) as int64) as percentile_80
        , cast(round(percentile_cont(monthly_avg, 0.60) over(partition by event_date_dt)) as int64) as percentile_60
        , cast(round(percentile_cont(monthly_avg, 0.40) over(partition by event_date_dt)) as int64) as percentile_40
    from 
        calc_monthly_avg
)

-- Add case for clicks percentile scoring logic
select
    event_date_dt
    , page_location_clean
    , total_12_months
    , months_live
    , first_seen_date
    , monthly_avg
    , percentile_80
    , percentile_60
    , percentile_40
    , case 
        when monthly_avg = 0 then 1
        when monthly_avg >= percentile_80 then 5
        when monthly_avg >= percentile_60 and monthly_avg < percentile_80 then 4
        when monthly_avg >= percentile_40 and monthly_avg < percentile_60 then 3
        when monthly_avg < percentile_40 then 2
    end as score_gsc_non_branded_queries
from 
    weekly_percentiles